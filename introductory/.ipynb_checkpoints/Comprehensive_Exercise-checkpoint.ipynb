{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYx6oEVKcE_L"
   },
   "source": [
    "# Exercise: putting everything together\n",
    "\n",
    "In this you will write code for a model that learns to classify mnist digits. You will use tensorflow, tracking training progress with matplotlib.\n",
    "\n",
    "For each sub-exercise, you have seen an example solution for it in one of the colabs leading up to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGBJLkR_cI3L"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from google.colab import files\n",
    "from scipy.stats import multivariate_normal\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "sns.set_style('ticks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gkBQpjJlCgP"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3049,
     "status": "ok",
     "timestamp": 1561538210102,
     "user": {
      "displayName": "David Szepesvari",
      "photoUrl": "https://lh4.googleusercontent.com/-djDv8j7EUOg/AAAAAAAAAAI/AAAAAAAAAEs/s9Ds-tUarwE/s64/photo.jpg",
      "userId": "06728915078212315022"
     },
     "user_tz": -60
    },
    "id": "nO_tMPdncmVy",
    "outputId": "4c684feb-ae3f-4f97-af15-4ee7c80cf85a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\n",
      "* input shape: (60000, 28, 28)\n",
      "* input min, mean, max: 0 33.318421449829934 255\n",
      "* input dtype: uint8\n",
      "* label shape: (60000,)\n",
      "* label min, mean, max: 0 4.4539333333333335 9\n",
      "* label dtype: uint8\n",
      "Number of test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Fetch the mnist data from tf.keras.datasets.mnist.\n",
    "\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Check what the data is like:\n",
    "print('Training dataset:')\n",
    "train_input, train_label = mnist_train\n",
    "print('* input shape:', train_input.shape)\n",
    "print('* input min, mean, max:', train_input.min(), train_input.mean(), train_input.max())\n",
    "print('* input dtype:', train_input.dtype)\n",
    "print('* label shape:', train_label.shape)\n",
    "print('* label min, mean, max:', train_label.min(), train_label.mean(), train_label.max())\n",
    "print('* label dtype:', train_label.dtype)\n",
    "\n",
    "test_input, test_label = mnist_test\n",
    "print('Number of test examples:', test_input.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "utL4ZmLrepoH"
   },
   "source": [
    "Normalize the data into the \\[0, 1\\] interval. It's also a good idea to check the class distribution, but here we know that this is OK.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60_4wXEPe7Ig"
   },
   "outputs": [],
   "source": [
    "# Normalize both train_input and test_input so that it is in [0, 1].\n",
    "#\n",
    "# Also ensure the following data types:\n",
    "#\n",
    "# * train_input and test_input need to be np.float32.\n",
    "# * the labels need to be converted to np.int32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDwRkDiYfzVO"
   },
   "outputs": [],
   "source": [
    "# We can visualize the first few training examples using matplotlib.imshow()\n",
    "# in combination with the gallery function we defined.\n",
    "#\n",
    "# Copy the gallery function in this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WQD1huVgV8Y"
   },
   "outputs": [],
   "source": [
    "# Show the first 6 training images on a 1x6 grid.\n",
    "# Remember to use grayscale plotting.\n",
    "# Also print their corresponding labels in the same order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VZdwYo_fUpo"
   },
   "outputs": [],
   "source": [
    "# Write a function that turns the data into tensorflow datasets and into\n",
    "# tensors corresponding to batches of examples, returning these tensors.\n",
    "#\n",
    "# The train data should be\n",
    "#\n",
    "# * shuffled across the full dataset\n",
    "# * repeated indefinitely\n",
    "# * batched at size 64.\n",
    "#\n",
    "# Simply batch the test data.\n",
    "#\n",
    "# IMPORTANT: Add a final (singleton) axis to the inputs; the conv nets that\n",
    "# we will use will expect this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3JcANwNfHuQ"
   },
   "outputs": [],
   "source": [
    "# Creata function that returns a network with the following structure:\n",
    "#\n",
    "# 1. Conv2D with 16 filters, kernel shape 3, stride 1, padding 'SAME'\n",
    "# 2. max pooling with window_shape [3, 3], srides [2, 2], padding 'SAME'\n",
    "# 3. ReLU\n",
    "# 4. Conv2D with 16 filters, kernel shape 3, stride 1, padding 'SAME'\n",
    "# 5. Flatten the final conv features using snt.BatchFlatten\n",
    "# 5. A Dense layer with output_size = 10, the number of classes.\n",
    "#\n",
    "# Make sure you use variable scoping to be able to share the underlying\n",
    "# variables.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRp2hrGofH7f"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "(train_inputs, train_labels), (test_inputs, test_labels) = get_tf_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g7daVkyoqS9p"
   },
   "outputs": [],
   "source": [
    "# * Get the output of the network on the training data,\n",
    "# * and the output of the *same* network with same weights on the test data.\n",
    "# * Use the `tf.nn.sparse_softmax_cross_entropy_with_logits` op to define the loss\n",
    "# * Define the train_op that minimizes the loss (averaged over the batch)\n",
    "#   using the `GradientDescentOptimizer`. Set the learning rate to 0.01.\n",
    "# * Get the initialization op.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wvmlucn6vbSD"
   },
   "outputs": [],
   "source": [
    "# Write a function that takes a list of losses and plots them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tufk2Xa2qTEI"
   },
   "outputs": [],
   "source": [
    "# Run the training loop, keeping track of losses and potentially the accuracy\n",
    "# on the training set. Plot the loss curve intermittently.\n",
    "#\n",
    "# The simplest solution would add a new plot with each plotting call. You\n",
    "# can play with the frequency of plotting (and recording) a bit in order\n",
    "# to find something that works.\n",
    "#\n",
    "# Based on the loss curves, decide how to set your total number of training\n",
    "# iterations. Once you are satified, add some code that evaluates your\n",
    "# prediction accuracy (not loss!) on the test set.\n",
    "#\n",
    "# Note that the outputs from the network are logits; for prediction accuracy\n",
    "# we can pick the most likely label and see if it is correct.\n",
    "\n",
    "# The accuracy (on the training set) you should expect:\n",
    "#\n",
    "# * Roughly 90% after 1000 training steps.\n",
    "# * 96-97% after 8k training steps.\n",
    "#\n",
    "# First iterate with 1k steps, if that works, train for 8k. 8k steps will\n",
    "# be roughly 8 minutes on CPU.\n",
    "#\n",
    "# The final test accuracy should also be ~96%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fwSrI-c2Cn3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xvt4bOeP1Bbo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ChrJA2KOqTMD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Comprehensive_Exercise.ipynb",
   "provenance": [
    {
     "file_id": "1r4IWzK2gHwXnbumu-1avZ9flg8ixREaM",
     "timestamp": 1530768533770
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
